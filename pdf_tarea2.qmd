---
title: "Tarea 2"
subtitle: "EYP3907 - Series de Tiempo"
format: 
  pdf: 
    include-in-header: 
      text: |
        \usepackage{amsmath}
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - right=20mm
      - heightrounded
    fig-pos: H
    classoption: twocolumn
    fontsize: 10pt
author: 
  - name: "Sebastián Celaya"
  - name: "Camila Echeverría"
  - name: "Francisca Vilca"
crossref:
  fig-title: Figura
  fig-prefix: figura
  tbl-title: Tabla
  tbl-prefix: tabla
tbl-cap-location: bottom
execute: 
  echo: false
  message: false
  warning: false
---

```{r}
library(lmtest)
library(splines)
library(forecast)
library(tidyverse)
library(dplyr)
library(tseries)
library(patchwork)
library(qqplotr)

source("TS.diag.R")
source("summary.arima.R")
source("salida.arima.R")
```

```{r}
datos <- read.table("norw001x-rwl-noaa.txt", header = TRUE)

datos <- datos %>%
  filter(!is.na(X540011_raw)) 

datos <- datos %>%
  filter(age_CE < 1890) %>% 
  select(age_CE,X540021_raw) %>% 
  rename("tiempo" = age_CE, "ancho" = X540021_raw)

Xt <- ts(datos$ancho, start = 1721, frequency = 1)
t <- as.numeric(time(Xt, start = 1721))
```

## Introducción

Utilizando una base de datos que contiene información sobre el ancho de los anillos de árboles pertenecientes a la especie *Pino Silvestre*, que puede encontrarse en el siguiente [link](https://www.ncei.noaa.gov/pub/data/paleo/treering/measurements/europe/norw001x-rwl-noaa.txt), ajustaremos un modelo ARMA y realizaremos diversos procedimientos para comprobar su ajuste.

## Análisis exploratorio

La @fig-exp1-1 muestra los valores del ancho del anillo registrados entre los años 1721 y 1889. 

```{r}
#| label: fig-exp1
#| fig-cap: "Sobre la serie de tiempo"
#| fig-subcap: 
#|     - "Variación"
#|     - "Boxplot"
#| layout-ncol: 2


datos %>%
  ggplot(aes(x = tiempo, y = ancho)) +
  geom_line(color = "brown4", lwd = 0.8)+
  geom_hline(yintercept = mean(datos$ancho),
             col = "darkgreen",lwd = 0.8) +
  labs(x = "Año", y = "Ancho anillo [mm]") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        axis.text.x = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15))

datos %>%
  ggplot(aes(x = ancho, y = 0)) +
  # geom_violin(color = "brown3") +
  geom_boxplot(fill = "brown4",
               width = 0.3,color = "darkgreen") +
  ylim(c(-0.5, 0.5)) +
  theme_bw() +
  xlab("Ancho anillo [mm]") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(size = 15),
        axis.title.x = element_text(size = 15)) 

```

Gracias a la @fig-exp1-2, es posible ver que la mediana de estos datos se encuentra cercana a 0.7 y que no tenemos datos atípicos, aunque la segunda mitad de las observaciones parecieran estar ligeramente más dispersa que la primera.

Luego, en los gráficos de la @fig-exp3 podemos ver la estructura de correlación de los datos. Si bien no se puede detectar estacionalidad a simple vista, las observaciones sí presentan altos niveles de correlación.




```{r}
#| label: fig-exp3
#| fig-cap: "Gráficos de autocorrelación"
#| fig-subcap: 
#|     - "ACF"
#|     - "PACF"
#| layout-ncol: 2

# ACF base
acf <- acf(Xt, plot = FALSE)
acf_data <- data.frame(Lag = acf$lag,
                       ACF = acf$acf)

# PACF base
pacf <- pacf(Xt, plot = FALSE)
pacf_data <- data.frame(Lag = pacf$lag,
                        PACF = pacf$acf)

n = nrow(datos)

ggplot(acf_data, aes(x = Lag, y = ACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "brown",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 17,
             col = "darkgreen") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))

pacf_data %>%
  ggplot(aes(x = Lag, y = PACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "brown",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 17,
             col = "darkgreen") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "PACF") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))

```



## Ajuste de un modelo ARMA

A simple vista, de los gráficos de ACF y PACF, vemos que nuestro modelo tiene estructura de un ARMA. Por lo que, ayudándonos de la función `auto.arima()` nuestra propuesta es un modelo arma(1,1), para que este sea capaz de capturar toda la estructura de la serie temporal. El modelo ajustado no considera diferenciación pues, como veremos más adelante, la serie no es estacional.

```{r}
#| include = F

fit <- forecast::Arima(Xt, order = c(1,0,1), include.mean = T)
```


### a) Significancia estadística de los coeficientes del modelo

Al revisar el valor-p asociado a cada coeficiente del modelo, es claro notar que todos son significativos, tal como se muestra en la Tabla 1:
\begin{table}[H]
  \centering
  \caption{Resumen de estimaciones}
  \begin{tabular}{lccc}
    \toprule
     & Estimation & Stand. E & p-value \\
    \midrule
    ar1        & 0.8367     & 0.0816         & 0.0000 \\
    ma1        & -0.5698    & 0.1209         & 0.0000 \\
    intercept  & 0.7079     & 0.0196         & 0.0000 \\
    \bottomrule
  \end{tabular}
  \label{tab:resultados}
\end{table}

### b) Estacionaridad e invertibilidad del modelo ARMA 

Una forma sencilla de comprobar la estacionalidad en los datos es con el test de Dickey-Fuller, el cual nos da un valor-p de 0.01 que rechaza la hipótesis nula de que los datos son estacionales. Por otro lado, una forma sencilla de verificar invertibilidad del modelo ARMA(1,1), es de forma gráfica, comprobando que los coeficientes se encuentren al interior de la circunferencia unitaria, lo que puede ser apreciado en la @fig-exp4:

```{r}
#| label: fig-exp4
#| fig-cap: "Gráfico de raíces unitarias"
#| fig-asp: 0.5
autoplot(fit) +
  theme_minimal() +
  labs(x = "", y = "") +
  theme(
    text = element_text(size = 10),
    axis.text.y = element_text(size = 8),
    axis.title.y = element_text(size = 8),
    axis.title.x = element_text(size = 8),
    axis.text.x = element_text(size = 8, angle = 90, vjust = 0.5, hjust=1),
    legend.position = "none"
  )
```


### c) Test de blancura - homocedasticidad y normalidad de los residuos

Los residuos del modelo deben cumplir estas propiedades. Para ello veremos diferentes test que se le pueden aplicar para comprobar ello:

- La @fig-exp5-1 nos muestra que los residuos efectivamente corresponden a ruido blanco, es decir, no están correlacionados.

- Luego, al realizar el test de Kolmogorov-Smirnov para evaluar la normalidad, el valor-p obtenido es de 0.27 aproximadamente, por lo que no se rechaza la hipótesis nula: los residuos provienen de una distribución normal. Este ajuste se puede observar en la @fig-exp5-2.

```{r}
#| label: fig-exp5
#| fig-cap: "Revisión de supuestos"
#| results: hide
#| layout-ncol: 2
#| fig-subcap: 
#|     - "Valores-p de Ljung-Box"
#|     - "Normalidad"

# dev.off()
# Box.Ljung.Test(fit$residuals, main = "", col = "brown")
gay.1 = "#FF0018"
gay.2 = "#FFA52C"
gay.3 = "#FFFF41"
gay.4 = "#008018"
gay.5 = "#0000F9"
gay.6 = "purple"
gayy = c(gay.1, gay.4, gay.6, gay.5)

ljung_box_test <- Box.Ljung.Test2(fit$residuals)

lb <- data.frame(Lag = 1:10, Pvalue = ljung_box_test)

ggplot(lb, aes(x = Lag, y = Pvalue)) +
  geom_point(shape = 8, size = 2,
             stat = "identity", col = "brown") +
  geom_hline(yintercept = 0.05,lwd =0.8,
             linetype = "dashed", color = "darkgreen") +
  labs(x = "Lag",
       y = "valor-p") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))

data.frame("res" = fit$residuals) %>% 
  ggplot(aes(sample = res)) +
  stat_qq_band(fill = gay.6, alpha = 0.4) +
  stat_qq_line(col = gay.1) +
  stat_qq_point(col = "darkgreen") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))
```


-De la misma manera, se obtiene un valor-p de 0.24 al realizar el test Breusch-Pagan para evaluar homocedasticidad, por lo que podemos concluir a favor de esta.

### d) ¿Es necesario realizar una transformación de Box-Cox?

Tras visualizar el gráfico de Box Ljung de @fig-exp5-1 se observa que *no* es necesario realizar una transformación de Box-Cox. Además si comparamos un modelo con y sin la transformación Box-Cox se puede observar que por AIC y BIC el mejor modelo es el modelo sin la transformación de Box-Cox, como se logra visualizar en Tabla 2

\begin{table}[H]
  \centering
  \caption{Comparación modelos}
  \begin{tabular}{lcc}
    \toprule
    Modelo & AIC & BIC \\
    \midrule
    Sin Box-Cox & -294.0414 & -281.5218 \\
    Con Box-Cox & -128.8216 & -116.302  \\
    \bottomrule
  \end{tabular}
  \label{tab:resultados}
\end{table}


# Predicciones

### a) Predicciones a un paso por el algoritmo Durbin-Levinson

```{r}
source("Durbin_Levinson.R")

## Durbin Levinson
fitted.durbinlevinson <- DurbinLevinson(Xt-mean(Xt), 
                                        ma = fit$coef[2],
                                        ar = fit$coef[1])$fitted

predicciones <- data.frame(anos = c(1889, 1890),
                           prediccion = c(0.61,
                                          forecast::forecast(fitted.durbinlevinson, h = 1)$mean + mean(Xt)),
                           inf_ci = c(0.61, 0.60678),
                           sup_ci = c(0.61, 0.7152417))

serie <- data.frame(ancho = datos$ancho, anos = t)
```

El algoritmo Durbin-Levinson, empleado para predicciones a un paso en series temporales, ha arrojado una estimación puntual de 0.6610. Este valor representa la proyección para el próximo periodo en la serie temporal. Acompañada por un intervalo de confianza que oscila entre 0.6067 y 0.7152, esta estimación proporciona una medida de la incertidumbre asociada, permitiendo una evaluación más completa de la fiabilidad de la predicción a corto plazo.

### b) ACF empírico vs teórico

Calculando el ACF de un ARMA(1, 1) y generando bandas de confianza utilizando el método Bartlett se generó la @fig-exp7. El análisis del ACF revela notables similitudes entre las autocorrelaciones empíricas y el patrón característico de un modelo ARMA (1,1) expuesto en @fig-exp7.

```{r}
#### Bandas de confianza:
# rho \in (rho(h) +- z*sqrt(w/n))
Bartlett = function(ma = NULL, ar = NULL, m = 3000, lag.max = 10){
  rho = ARMAacf(ma = ma, ar = ar, lag.max = lag.max+m)
  j = 1:m
  w = c()
  for(h in 1:lag.max){
    w[h] = sum((rho[abs(h+j)+1]+rho[abs(h-j)+1]-2*rho[h+1]*rho[j+1])^2)
  }
  w
}
n <- length(Xt)
w <- Bartlett(ar = coef(fit)[1], ma = coef(fit)[2], lag.max = 22)

# Banda de confianza para el acf empirico
rhoh <- acf(Xt, lag.max = 22, plot = FALSE)$acf[2:23]

IC_inf <- rhoh - qnorm(1 - 0.05/2)*sqrt(w/n)
IC_sup <- rhoh + qnorm(1 - 0.05/2)*sqrt(w/n)

acf_teo <- ARMAacf(ar = coef(fit)[1], ma = coef(fit)[2], lag.max = 22)
IC <- data.frame(IC_inf = IC_inf, IC_sup = IC_sup)

aux <- acf(Xt, plot = FALSE)
```

```{r}
#| label: fig-exp7
#| fig-cap: "ACF empírico vs teórico"
#| fig-asp: 0.5

data.frame(ACF = acf_teo, Lag = 0:(length(acf_teo) - 1)) %>%
  ggplot(aes(x = Lag,
             y = ACF)) +
  geom_hline(yintercept = 0, col = "gray33") +
  geom_point(aes(color = "ACF teórico"),
             size = 2,
             shape = 17) +
  geom_segment(data = data.frame(ACF = aux$acf, Lag = aux$lag),
               aes(x = Lag, xend = Lag,
                   y = ACF, yend = 0, color = "ACF empírico")) +
  geom_hline(yintercept = 1.96/sqrt(169),
             col = "red", linetype = "dashed") +
  geom_hline(yintercept = -1.96/sqrt(169),
             col = "red", linetype = "dashed") +
  geom_line(data = IC, aes(x = 1:22,
                           y = IC_inf,
                           col = "Banda de confianza")) +
  geom_line(data = IC, aes(x = 1:22,
                           y = IC_sup,
                           col = "Banda de confianza")) +
  scale_color_manual(values = c("ACF teórico" = "darkgreen",
                                "ACF empírico" = "brown4",
                                "Banda de confianza" = "blue")) +
  labs(y = "ACF", 
       x = "Lag",
       colour = "") +
  theme_bw() +
  theme(legend.text = element_text(size = 10),
        axis.title.y = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        legend.position = "bottom", 
        legend.box = "horizontal") 
```

### c) Periodograma vs Densidad espectral

En la evaluación del modelo ARMA(1,1) en series temporales, se destacó una notable correspondencia entre las características espectrales predichas y la estructura observada en el Periodograma. La similitud entre los picos de frecuencia en la Densidad Espectral del modelo y las elevaciones en el Periodograma respalda la capacidad del ARMA(1,1) para capturar eficazmente las componentes temporales. Esta convergencia entre la Densidad Espectral y el Periodograma subraya la precisión del modelo al reflejar la variabilidad en los datos, proporcionando una herramienta valiosa para el análisis de la dinámica temporal.

```{r}
spec <- LSTS::spectral.density(ar = fit$coef[1], ma = fit$coef[2],
                               sd = sqrt(fit$sigma2))
per <- LSTS::periodogram(Xt)
```

```{r}
#| label: fig-exp10
#| fig-cap: "Comparación"
#| fig-subcap: 
#|     - "Densidad espectral"
#|     - "Periodograma"
#| layout-ncol: 2

data.frame(a = spec) %>%
  ggplot(aes(x = 1:315, y = a)) +
  geom_line() +
  labs(x = "", y = "Densidad espectral") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))

data.frame(a = per$periodogram) %>%
  ggplot(aes(x = 1:84, y = a)) +
  geom_line() +
  labs(x = "", y = "Periodograma") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 15),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 12),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 15))


```


## Método de Whittle

```{r}
#| include: false

whittle.loglik = function(x, serie, p = 1, q = 1){
  Y = serie
  n = length(Y)
  ar  = x[1:p]
  ma  = x[(p+1):(p+q)]
  if(p == 0){ar = numeric()}
  if(q == 0){ma = numeric()}
  sigma = x[p+q+1]
  aux = LSTS::periodogram(Y, plot = F)
  I = aux$periodogram
  lambda = aux$lambda
  f = LSTS::spectral.density(ar = ar, ma = ma, sd = sigma, lambda = lambda)
  aux = 0.5*(sum(log(f)) + sum(I/f))/n
  aux
}

whittle <- nlminb(start = c(0.5, 0.5,0.5), objective = whittle.loglik, serie = Xt, p = 1, q = 1)$par

fit_whittle <-  forecast::Arima(Xt-mean(Xt), order = c(1,0,1), fixed = whittle[1:2], include.mean = F)

fitted_whittle.auto.arima <- fit_whittle$fitted

sum_w <- summary(fit_whittle)

# De la cosa de la cami a ti vilkis
whittle_p <- forecast::forecast(fitted_whittle.auto.arima, h = 1)$mean + mean(Xt)
whittle_ci <- forecast::forecast(fitted_whittle.auto.arima, h = 1)$lower + mean(Xt)
whittle_cs <- forecast::forecast(fitted_whittle.auto.arima, h = 1)$upper + mean(Xt)
```

Ahora si se ajustan los datos con el método de Whittle, también con un modelo ARMA(1,1), obtenemos coeficientes significativos. Además, si usamos la función `forecast()` obtenemos que la predicción de la dimensión del anillo para el siguiente año es de `r round(whittle_p[1],3)` y construyendo un intervalo de confianza al $95\%$ es de [`r round(whittle_ci[2],3)`,`r round(whittle_cs[2],3)`]. Los cuales al compararlos con los obtenidos con el método de Durvin-Levinson vemos que las diferencias son mínimas.

Una forma sencilla de comparar los ajustes es mediantes un gráfico de líneas para visualizar que tanto logran extraer la información de los datos originales como en la @fig-11

```{r}
#| label: fig-11
#| fig-cap: "Compara"
#| fig-asp: 0.5

gay.1 = "#FF0018"
gay.2 = "#FFA52C"
gay.3 = "#FFFF41"
gay.4 = "#008018"
gay.5 = "#0000F9"
gay.6 = "purple"
gay = c(gay.1, gay.4, gay.6, gay.5)

ajuste = c(Xt, fit$fitted, fitted.durbinlevinson + mean(Xt), fitted_whittle.auto.arima + mean(Xt))
tipo = c(rep("original", length(Xt)), rep("arma", length(Xt)), rep("durvin-levinson", length(Xt)), rep("whittle", length(Xt)))
comparar <- data.frame(ajuste, tipo, fecha = c(1721:1889))

comparar %>% 
  ggplot(aes(fecha, ajuste, color = tipo)) +
  geom_line(size = 0.8, alpha = 0.5) +
  scale_color_manual(values = gay) + 
  labs(x = "Fecha",
       y = "Valor") +
  theme_minimal()+
  theme(legend.position = "bottom") +
  guides(linetype = guide_legend(override.aes = list(color = "black")))
```

De la fig exp6, vemos claramente que el ajuste mediante el algortimo de Durvin-Levinson y por el de Whittle, son bastantes similares, por lo mismo sus predicciones tambien lo son. Por otro lado, vemos como el modelo arma no logra capturar por completo la variabilidad de los datos como si lo hacen los otros métodos.

## Comparación de ajustes

Finalmente, una forma bastante sencilla de comparar los modelos es mediante medidas para evaluar el error las cuales se presentan en la tabla n+1 

\begin{table}[H]
\centering
\begin{tabular}{| c | c | c | c | c | c | c | c |}
\hline
 & ME & RMSE & MAE & MPE & MAPE & MASE \\
\hline
ARMA & 0.15 & 0.12 & 16.35 & MPE & MAPE & MASE\\
\hline
D-L & 0.23 & 0.14 & 17.00 & MPE & MAPE & MASE\\
\hline
Whittle & 0.23 & 0.14 & 17.00 & MPE & MAPE & MASE\\
\bottomrule
\end{tabular}
\caption{Medidas de calidad de ajuste}
\label{tab:cuartiles}
\end{table}