---
title: "Tarea 2"
subtitle: "EYP3907 - Series de Tiempo"
format: 
  pdf: 
    include-in-header: 
      text: |
        \usepackage{amsmath}
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - right=20mm
      - heightrounded
    fig-pos: H
    classoption: twocolumn
author: 
  - name: "Sebastián Celaya"
  - name: "Camila Echeverría"
  - name: "Francisca Vilca"
crossref:
  fig-title: Figura
  fig-prefix: figura
  tbl-title: Tabla
  tbl-prefix: tabla
tbl-cap-location: bottom
execute: 
  echo: false
  message: false
  warning: false
---

```{r}
library(lmtest)
library(splines)
library(forecast)
library(tidyverse)
library(dplyr)
library(tseries)
library(patchwork)

source("TS.diag.R")
source("summary.arima.R")
source("salida.arima.R")
```

```{r}
datos <- read.table("norw001x-rwl-noaa.txt", header = TRUE)

datos <- datos %>%
  filter(!is.na(X540011_raw)) 

datos <- datos %>%
  filter(age_CE < 1890) %>% 
  select(age_CE,X540021_raw) %>% 
  rename("tiempo" = age_CE, "ancho" = X540021_raw)

Xt <- ts(datos$ancho, start = 1721, frequency = 1)
t <- as.numeric(time(Xt, start = 1721))
```

## Introducción

Utilizando una base de datos que contiene información sobre el ancho de los anillos de árboles pertenecientes a la especie *Pino Silvestre*, que puede encontrarse en el siguiente [link](https://www.ncei.noaa.gov/pub/data/paleo/treering/measurements/europe/norw001x-rwl-noaa.txt), ajustaremos un modelo ARMA y realizaremos diversos procedimientos para comprobar su ajuste.

## Análisis exploratorio

La @fig-exp1 muestra los valores del ancho del anillo registrados entre los años 1721 y 1889. 

```{r}
#| label: fig-exp1
#| fig-cap: "Variación del ancho del anillo"
#| fig-asp: 0.5

datos %>%
  ggplot(aes(x = tiempo, y = ancho)) +
  geom_line(color = "brown4", lwd = 0.8)+
  geom_hline(yintercept = mean(datos$ancho),
             col = "darkgreen",lwd = 0.8) +
  labs(x = "Año", y = "Ancho anillo [mm]") +
  theme_bw()

```

Gracias a la @fig-exp2, es posible ver que la mediana de estos datos se encuentra cercana a 0.7 y que no tenemos datos atípicos, aunque la segunda mitad de las observaciones parecieran estar ligeramente más dispersa que la primera.

```{r}
#| label: fig-exp2
#| fig-cap: "Boxplot de ancho de anillo"
#| fig-asp: 0.5

datos %>%
  ggplot(aes(x = ancho, y = 0)) +
  # geom_violin(color = "brown3") +
  geom_boxplot(fill = "brown4",
               width = 0.3,color = "darkgreen") +
  ylim(c(-0.5, 0.5)) +
  theme_bw() +
  xlab("Ancho anillo [mm]") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        plot.subtitle = element_text(size = 9,
                                     #face = "bold",
                                     color = "black",
                                     hjust = 0.5),
        axis.title.x = element_text(size = 8)) 

```


```{r}
#| label: fig-exp3
#| fig-cap: "Gráfico de Autocorrelación"
#| fig-asp: 0.5

# ACF base
acf <- acf(Xt, plot = FALSE)
acf_data <- data.frame(Lag = acf$lag,
                       ACF = acf$acf)

# PACF base
pacf <- pacf(Xt, plot = FALSE)
pacf_data <- data.frame(Lag = pacf$lag,
                        PACF = pacf$acf)

n = nrow(datos)

ggplot(acf_data, aes(x = Lag, y = ACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "brown",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 17,
             col = "darkgreen") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))


```

```{r}
#| label: fig-exp4
#| fig-cap: "Gráfico de Autocorrelación Parcial"
#| fig-asp: 0.5

pacf_data %>%
  ggplot(aes(x = Lag, y = PACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "darkgreen") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "brown",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 17,
             col = "darkgreen") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "PACF") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))


```

Luego, en los gráficos de la @fig-exp3 y la @fig-exp4 podemos ver la estructura de correlación de los datos. Si bien no se puede detectar estacionalidad a simple vista, las observaciones sí presentan altos niveles de correlación.

## Ajuste de un modelo ARMA

A simple vista, de los gráficos de ACF y PACF, vemos que nuestro modelo tiene estructura de un ARMA. Sin embargo, al usar la función `auto.arima()` como guía se recomienda usar un modelo MA(1), pero al hacerle las pruebas a los residuos, este rechaza el test de blancura. Por lo que, nuestra propuesta es un modelo arma(1,1), para que este sea capaz de capturar toda la estructura de la serie temporal.

```{r}
#| include = F

fit <- forecast::Arima(Xt, order = c(1,0,1), include.mean = F)
```


### a) Significancia estadística de los coeficientes del modelo

Sabemos que los coeficientes del modelo deben cumplir con ser estadísticamente significantes, por lo que al revisar el valor-p asociado a cada coeficiente del modelo, es claro notar que todos son significativos, tal como se muestra en la Tabla 1:

\begin{table}[H]
  \centering
  \caption{Resumen de estimaciones}
  \begin{tabular}{lccc}
    \toprule
     & Estimation & Stand. E & p-value \\
    \midrule
    ar1        & 0.8367     & 0.0816         & 0.0000 \\
    ma1        & -0.5698    & 0.1209         & 0.0000 \\
    intercept  & 0.7079     & 0.0196         & 0.0000 \\
    \bottomrule
  \end{tabular}
  \label{tab:resultados}
\end{table}

### b) Estacionaridad e invertibilidad del modelo ARMA 

Una forma sencilla de comprobar la estacionalidad en los datos es con el test de Dickey-Fuller, el cual nos da un valor-p de 0.01 que al ser menor al $5\%$ de significancia se rechaza la hipótesis nula de que los datos son estacionales. Por otro lado, una forma sencilla de verificar invertibilidad del modelo ARMA(1,1), es de forma gráfica, comprobando que los coeficientes se encuentren al interior de la circunferencia unitaria, lo que puede ser apreciado en la @fig-exp5 :

```{r}
#| label: fig-exp5
#| fig-cap: "Gráfico de raíces unitarias"
#| fig-asp: 0.5
autoplot(fit) +
  theme_minimal() +
  labs(x = "", y = "") +
  theme(
    text = element_text(size = 10),
    axis.text.y = element_text(size = 8),
    axis.title.y = element_text(size = 8),
    axis.title.x = element_text(size = 8),
    axis.text.x = element_text(size = 8, angle = 90, vjust = 0.5, hjust=1),
    legend.position = "none"
  )
```


### c) Test de blancura - homocedasticidad y normalidad de los residuos

Sabemos que los residuos del modelo, es decir, lo que no es capaz de explicar el modelo ARMA(1,1), debe cumplir con ser normales, tener varianza constante e idealmente provenir de un ruido blanco. Para ello veremos diferentes test que se le pueden aplicar para comprobar ello:

- Usando el estadístico de Ljung-Box es

```{r fig.width = 10, fig.height = 4}
#| label: fig-exp6
#| fig-cap: "Gráfico de valores-p para el estadístico Ljung-Box"
#| fig-asp: 0.5

# dev.off()
# Box.Ljung.Test(fit$residuals, main = "", col = "brown")

ljung_box_test <- Box.Ljung.Test2(fit$residuals)

lb <- data.frame(Lag = 1:10, Pvalue = ljung_box_test)

ggplot(lb, aes(x = Lag, y = Pvalue)) +
  geom_point(shape = 8, size = 2,
             stat = "identity", col = "brown") +
  geom_hline(yintercept = 0.05,lwd =0.8,
             linetype = "dashed", color = "darkgreen") +
  labs(x = "Lag",
       y = "valor-p") +
  theme_minimal()
```

### d) ¿Es necesario realizar una transformación de Box-Cox?

Tras visualizar el gráfico de Box Ljung de *INSERTAR NUMERO DEL GRÁFICO* se observa que *no* es necesario realizar una transformación de Box-Cox. Además si comparamos un modelo con y sin la transformación Box-Cox se puede observar que por AIC y BIC el mejor modelo es el modelo sin la transformación de Box-Cox, como se logra visualizar en Tabla 2

\begin{table}[H]
  \centering
  \caption{Comparación modelos}
  \begin{tabular}{lcc}
    \toprule
    Modelo & AIC & BIC \\
    \midrule
    Sin Box-Cox & -294.0414 & -281.5218 \\
    Con Box-Cox & -128.8216 & -116.302  \\
    \bottomrule
  \end{tabular}
  \label{tab:resultados}
\end{table}


# Predicciones

### a) Predicciones a un paso por el algoritmo Durbin-Levinson

Tras haber ajustado un modelo ARMA(1, 1) se generaron predicciones del modelo.

```{r}
source("Durbin_Levinson.R")

## Durbin Levinson
fitted.durbinlevinson <- DurbinLevinson(Xt-mean(Xt), 
                                        ma = fit$coef[2],
                                        ar = fit$coef[1])$fitted

predicciones <- data.frame(anos = c(1889, 1890),
                           prediccion = c(0.61,
                                          forecast::forecast(fitted.durbinlevinson, h = 1)$mean + mean(Xt)),
                           inf_ci = c(0.61, 0.60678),
                           sup_ci = c(0.61, 0.7152417))

serie <- data.frame(ancho = datos$ancho, anos = t)
```

```{r, fig.width = 10, fig.height = 4}
#| label: fig-exp7
#| fig-cap: "Predicción a un paso por Durbin-Levinson"
#| fig-asp: 0.5

ggplot() +
  geom_line(data = serie[-c(1:165), ], aes(x = anos, y = ancho), color = "brown4") +
  geom_ribbon(data = predicciones, aes(x = anos, ymin = inf_ci, ymax = sup_ci),
              fill = "darkgreen", alpha = 0.51) +
  geom_segment(aes(x = 1889, xend = 1890, y = 0.61, yend = 0.6610108),
               color = "blue") +
  labs(x = "Años",
       y = "Ancho anillos") +
  theme_bw()

```

\begin{table}[H]
  \centering
  \caption{Predicción a un paso Durbin-Levinson}
  \begin{tabular}{lcc}
    \toprule
    Estimación Puntual & IC superior & IC inferior \\
    \midrule
    0.6610108 & 0.7152417 & 0.60678 \\
    \bottomrule
  \end{tabular}
  \label{tab:resultados}
\end{table}

### ACF empírico vs teórico

Calculando el ACF de un ARMA(1, 1) y generando bandas de confianza utilizando el método Bartlett se generó el INSERTAR NUMERO DEL GRÁFICO. El análisis del ACF revela notables similitudes entre las autocorrelaciones empíricas y el patrón característico de un modelo ARMA (1,1) expuesto en INSERTAR NUMERO DE LA FIGURA.

```{r}
#### Bandas de confianza:
# rho \in (rho(h) +- z*sqrt(w/n))
Bartlett = function(ma = NULL, ar = NULL, m = 3000, lag.max = 10){
  rho = ARMAacf(ma = ma, ar = ar, lag.max = lag.max+m)
  j = 1:m
  w = c()
  for(h in 1:lag.max){
    w[h] = sum((rho[abs(h+j)+1]+rho[abs(h-j)+1]-2*rho[h+1]*rho[j+1])^2)
  }
  w
}
n <- length(Xt)
w <- Bartlett(ar = coef(fit)[1], ma = coef(fit)[2], lag.max = 22)

# Banda de confianza para el acf empirico
rhoh <- acf(Xt, lag.max = 22, plot = FALSE)$acf[2:23]

IC_inf <- rhoh - qnorm(1 - 0.05/2)*sqrt(w/n)
IC_sup <- rhoh + qnorm(1 - 0.05/2)*sqrt(w/n)

acf_teo <- ARMAacf(ar = coef(fit)[1], ma = coef(fit)[2], lag.max = 22)
IC <- data.frame(IC_inf = IC_inf, IC_sup = IC_sup)

aux <- acf(Xt, plot = FALSE)
```

```{r, fig.width = 10, fig.height = 4}
#| label: fig-exp8
#| fig-cap: "ACF empírico vs teórico"
#| fig-asp: 0.5

data.frame(ACF = acf_teo, Lag = 0:(length(acf_teo) - 1)) %>%
  ggplot(aes(x = Lag,
             y = ACF)) +
  geom_hline(yintercept = 0, col = "gray33") +
  geom_point(aes(color = "ACF teórico"),
             size = 2,
             shape = 17) +
  geom_segment(data = data.frame(ACF = aux$acf, Lag = aux$lag),
               aes(x = Lag, xend = Lag,
                   y = ACF, yend = 0, color = "ACF empírico")) +
  geom_hline(yintercept = 1.96/sqrt(169),
             col = "red", linetype = "dashed") +
  geom_hline(yintercept = -1.96/sqrt(169),
             col = "red", linetype = "dashed") +
  geom_line(data = IC, aes(x = 1:22,
                           y = IC_inf),
            col = "blue") +
  geom_line(data = IC, aes(x = 1:22,
                           y = IC_sup),
            col = "blue") +
  scale_color_manual(values = c("ACF teórico" = "darkgreen",
                                "ACF empírico" = "brown4")) +
  theme(legend.position = "bottom", legend.box = "horizontal") +
  labs(y = "ACF", 
       x = "Lag") +
  theme_bw()
```

### Periodograma vs Densidad espectral

Durante la evaluación de nuestro modelo ARMA(1,1) en las series temporales, hemos observado una notable afinidad entre las características espectrales previstas por el modelo y la estructura evidente en el Periodograma como se muestra en INSERTAR NUMERO DEL GRÁFICO. Los picos de frecuencia destacados en la Densidad Espectral del modelo revelan una similitud con las elevaciones observadas en el Periodograma, indicando una alineación espectral acorde entre las predicciones del ARMA(1,1) y las características temporales de los datos *(acortable a indicando un parecido entre las predicciones del ARMA(1,1) y los datos temporales)*.

Esta relación robusta respalda el uso del modelo ARMA(1,1) para capturar eficazmente las componentes temporales en nuestras series temporales. La convergencia entre la Densidad Espectral y el Periodograma demuestra la capacidad del modelo para reflejar fielmente la variabilidad en los datos, proporcionando una valiosa herramienta para el análisis y la interpretación de la dinámica temporal.

```{r}
spec <- LSTS::spectral.density(ar = fit$coef[1], ma = fit$coef[2],
                               sd = sqrt(fit$sigma2))
per <- LSTS::periodogram(Xt)
```

```{r, fig.width = 10, fig.height = 4}
#| label: fig-exp9
#| fig-cap: "Densidad espectral vs Periodograma"
#| fig-asp: 0.5

data.frame(a = spec) %>%
  ggplot(aes(x = 1:315, y = a)) +
  geom_line() +
  labs(x = "", y = "Densidad espectral") +
  theme_bw()

data.frame(a = per$periodogram) %>%
  ggplot(aes(x = 1:84, y = a)) +
  geom_line() +
  labs(x = "", y = "Periodograma") +
  theme_bw()
```